---
title: "glmmTMB models"
author: "Sarah Popov"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(formatR)

knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE, 
                      message = FALSE,
                      tidy.opts = list(width.cutoff = 60), 
                      tidy = TRUE)

# Color palette (using blue & yellow from wesanderson Zissou1 palette)
pal <- c(rgb(86, 152, 175, maxColorValue = 255), rgb(229, 205, 79, maxColorValue = 255))

# Source the data file, which connects to the bppeeps database and then queries and processes the data
# This will produce two datasets: 
# 1) dat [counts + environmental covariates]
# 2) sr [daily species ratios]
source(here::here("models", "prepare_dat.R"))
source(here::here("models", "binomial_sr.R"))
```

```{r merge sr results in, include = FALSE}
# Add predicted wesa ratio generated above to the dat dataset
dat <- merge(dat, yrs[,c("year", "julian_day", "predicted_ratio")], 
             by = c("year", "julian_day"))

# Scale and log-transform variables of interest
dat$predicted_wesa <- round(dat$final_count * dat$predicted_ratio, 0)
dat$predicted_dunl <- dat$final_count - dat$predicted_wesa
dat$log_wesa <- log(dat$predicted_wesa + 1)
dat$log_dunl <- log(dat$predicted_dunl + 1)
dat$year_c <- scale(as.numeric(dat$year))

# Remove records with NA in important environmental covariates
dat <- dat[!is.na(dat$flow) & !is.na(dat$total_precip),]

# Proportion of zeroes
dat_p0 <- sum(dat$predicted_wesa == 0) / length(dat$predicted_wesa)
```

```{r aggregate by NS, include=FALSE}
dat3 <- sqldf::sqldf("select year, 
                      survey_date, 
                      julian_day, 
                      min(start_time) as start_time, 
                      n_s, 
                      sum(final_count) as final_count, 
                      sum(predicted_wesa) as predicted_wesa, 
                      sum(predicted_dunl) as predicted_dunl, 
                      p_wesa, 
                      predicted_ratio, 
                      avg(raptor_count) as raptor_count, 
                      tide,
                      elev_min, 
                      elev_max, 
                      elev_median, 
                      elev_mean, 
                      elev_range, 
                      flow, 
                      total_precip, 
                      mean_temp, 
                      u, 
                      v, 
                      windspd, 
                      wind_deg 
                      from dat 
                      group by survey_date, n_s;") %>%
  dplyr::mutate(dos = scale(julian_day),
                log_wesa = log(predicted_wesa + 1),
                log_dunl = log(predicted_dunl + 1),
                year_n = as.numeric(year),
                year_c = scale(year_n)) %>%
  dplyr::select(year, survey_date, julian_day, dos, start_time, n_s,
                final_count, predicted_wesa, predicted_dunl, log_wesa, 
                log_dunl, dplyr::everything())

# Proportion of zeroes
dat3_p0 <- sum(dat3$predicted_wesa == 0) / length(dat3$predicted_wesa)
```


# WESA ZIP + ZINB base models 

## By station

### Data summary

Dataset: one count record per station per survey date, `nrow(dat)` records. `round(dat_p0*100, 1)`% of the records are zeroes.

```{r station response distribution, fig.cap="Histogram of WESA count per station per survey date. Plenty of zeroes..."}
hist(dat$predicted_wesa,  breaks = 100, main = "Histogram of WESA count", xlab = "WESA count")
```

```{r wesa response vs all vars p1}
(dat %>%
  dplyr::select(predicted_wesa, year, julian_day, dos, raptor_count, elev_min, elev_max, elev_median, elev_mean, elev_range, flow, total_precip, mean_temp, u, v, windspd, wind_deg) %>%
  tidyr::gather(-predicted_wesa, key = "var", value = "value") %>%
  dplyr::mutate(value = as.numeric(value)) %>%
  ggplot(aes(x = value, y = predicted_wesa)) +
  geom_point(size = 0.3) +
  geom_smooth() +
  scale_x_continuous(n.breaks = 3) +
  ggtitle("Full dataset variables vs. WESA count") + 
  ggforce::facet_wrap_paginate(~ var, ncol = 3, nrow = 3, scales = "free", page = 1) +
  theme_minimal())
```
```{r wesa response vs all vars p2}
(dat %>%
  dplyr::select(predicted_wesa, year, julian_day, dos, raptor_count, elev_min, elev_max, elev_median, elev_mean, elev_range, flow, total_precip, mean_temp, u, v, windspd, wind_deg) %>%
  tidyr::gather(-predicted_wesa, key = "var", value = "value") %>%
  dplyr::mutate(value = as.numeric(value)) %>%
  ggplot(aes(x = value, y = predicted_wesa)) +
  geom_point(size = 0.3) +
  geom_smooth() +
  scale_x_continuous(n.breaks = 3) +
  ggtitle("Full dataset variables vs. WESA count") + 
  ggforce::facet_wrap_paginate(~ var, ncol = 3, nrow = 3, scales = "free", page = 2) +
  theme_minimal())
```
```{r wesa correlation plot, fig.cap="Correlation matrix between numeric explanatory variables."}
dat %>%
    dplyr::select(predicted_wesa, julian_day, dos, elev_min, elev_max, elev_median, elev_mean, elev_range, flow, total_precip, mean_temp, u, v, windspd, wind_deg) %>% 
  cor() %>% 
  corrplot::corrplot(order="hclust")
```



### Base models

```{r station zero inflated baseline models}
## Poisson and negative binomial models
fit_poisson <- glmmTMB::glmmTMB(predicted_wesa ~ station_n + year_c +  dos + I(dos^2) + (dos + I(dos^2) | year) + (1|year),
                                data = dat, 
                                ziformula = ~0, # no zero inflation 
                                family = "poisson")
fit_binom1 <- update(fit_poisson, family = glmmTMB::nbinom1) 
fit_binom2 <- update(fit_poisson, family = glmmTMB::nbinom2) # negative binomial with a different variance function

## zero-inflation models
fit_zipoisson <- glmmTMB::glmmTMB(predicted_wesa ~ station_n + year_c +  dos + I(dos^2) + (dos + I(dos^2) | year) + (1|year),
                         data = dat,  
                         ziformula = ~1,
                         family = "poisson")
fit_zinbinom1 <- update(fit_zipoisson, family = glmmTMB::nbinom1) 
fit_zinbinom2 <- update(fit_zipoisson, family = glmmTMB::nbinom2) # negative binomial with a different variance function

# compare models with AIC
bbmle::AICtab(fit_poisson, fit_binom1, fit_binom2, fit_zipoisson, fit_zinbinom1, fit_zinbinom2) 

bestfit_dat <- fit_zinbinom1
```

- Results of `glmmTMB::diagnose()` suggest certain random effects structures fail to converge: `(dos + I(dos^2) | n_s)` and `(dos + I(dos^2) | station_n)` both fail. 
- A zero-inflation model is definitely the way to go, as the non-zi formula models fail to converge.
- There are potentially too many zeroes in this dataset than would be expected with a Poisson distribution. While it's certainly possible to run these models with Poisson distributions, it seems assuming a *negative binomial* distribution in the response variable makes more sense.

### Simulate best-fit model

Simulate the best-fit model, **`fit_zinbinom1`**, 10,000 times to get the expected distribution of zero-values. The red line is the true proportion of zero-values from the data itself (`dat_p0`). 

```{r, fig.cap="Best-fit model distribution of zeroes vs. observed proportion of zeroes (red line). The model over-estimates the amount of zeroes observed in our dataset.", echo=FALSE}
set.seed(101)
system.time(
    pp <- replicate(10000, mean(simulate(bestfit_dat)[[1]] == 0))
)
par(las=1, bty = "l")
plot(prop.table(table(pp))) + abline(v = dat_p0, col = 2)
```


## By North vs. South

Dataset: one count record per N/S division per survey date, `nrow(dat3)` records. `round(dat_p3*100, 1)`% of the records are zeroes.

```{r n_s response distribution, fig.cap="Histogram of WESA count per north/south region per survey date. Also plenty of zeroes...!"}
hist(dat3$predicted_wesa,  breaks = 100, main = "Histogram of WESA count", xlab = "WESA count")
```
```{r wesa n_s response vs all vars p1}
(dat3 %>%
  dplyr::select(predicted_wesa, year, julian_day, dos, raptor_count, elev_min, elev_max, elev_median, elev_mean, elev_range, flow, total_precip, mean_temp, u, v, windspd, wind_deg) %>%
  tidyr::gather(-predicted_wesa, key = "var", value = "value") %>%
  dplyr::mutate(value = as.numeric(value)) %>%
  ggplot(aes(x = value, y = predicted_wesa)) +
  geom_point(size = 0.3) +
  geom_smooth() +
  scale_x_continuous(n.breaks = 3) +
  ggtitle("Full dataset variables vs. WESA count (data grouped by N/S station)") + 
  ggforce::facet_wrap_paginate(~ var, ncol = 3, nrow = 3, scales = "free", page = 1) +
  theme_minimal())
```

```{r wesa n_s response vs all vars p2}
(dat3 %>%
  dplyr::select(predicted_wesa, year, julian_day, dos, raptor_count, elev_min, elev_max, elev_median, elev_mean, elev_range, flow, total_precip, mean_temp, u, v, windspd, wind_deg) %>%
  tidyr::gather(-predicted_wesa, key = "var", value = "value") %>%
  dplyr::mutate(value = as.numeric(value)) %>%
  ggplot(aes(x = value, y = predicted_wesa)) +
  geom_point(size = 0.3) +
  geom_smooth() +
  scale_x_continuous(n.breaks = 3) +
  ggtitle("Full dataset variables vs. WESA count (data grouped by N/S station)") + 
  ggforce::facet_wrap_paginate(~ var, ncol = 3, nrow = 3, scales = "free", page = 2) +
  theme_minimal())
```

```{r wesa n_s correlation plot, fig.cap="Correlation matrix between numeric explanatory variables (data grouped by N/S station)."}
dat3 %>%
    dplyr::select(predicted_wesa, julian_day, dos, elev_min, elev_max, elev_median, elev_mean, elev_range, flow, total_precip, mean_temp, u, v, windspd, wind_deg) %>% 
  cor() %>% 
  corrplot::corrplot(order="hclust")
```


### Base models

```{r n_s zero inflated baseline models}
## Poisson and negative binomial models
fit_poisson <- glmmTMB::glmmTMB(predicted_wesa ~ n_s + year_c +  dos + I(dos^2) + (1|year),
                                data = dat3, 
                                ziformula = ~0, # no zero inflation 
                                family = "poisson")
fit_binom1 <- update(fit_poisson, family = glmmTMB::nbinom1) 
fit_binom2 <- update(fit_poisson, family = glmmTMB::nbinom2) # negative binomial with a different variance function

## zero-inflation models
fit_zipoisson <- glmmTMB::glmmTMB(predicted_wesa ~ n_s + year_c +  dos + I(dos^2) + (1|year),
                         data = dat3,  
                         ziformula = ~1,
                         family = "poisson")
fit_zinbinom1 <- update(fit_zipoisson, family = glmmTMB::nbinom1) 
fit_zinbinom2 <- update(fit_zipoisson, family = glmmTMB::nbinom2) # negative binomial with a different variance function

# compare models with AIC
bbmle::AICtab(fit_poisson, fit_binom1, fit_binom2, fit_zipoisson, fit_zinbinom1, fit_zinbinom2)

bestfit_dat3 <- fit_zinbinom1
```
- Similar to above, the `(dos + I(dos^2) | year)` random effect term causes nearly all models to fail to converge. The term was removed.
- Also similar to above, best-fit model is a ZI negative binomial model.

### Simulate best-fit model

Simulate the best-fit model, **`fit_zinbinom2`**, 10,000 times to get the expected distribution of zero-values. The red line is the true proportion of zero-values from the data itself (`dat3_p0`). 

```{r, fig.cap="Best-fit model distribution of zeroes vs. observed proportion of zeroes (red line). The base model does a fairly good job of estimating the correct proportion of zeroes, but still slgihtly overestimates.", echo=FALSE}
plot.new()
set.seed(101)
system.time(
    pp <- replicate(10000, mean(simulate(bestfit_dat3)[[1]] == 0))
)
par(las=1, bty = "l")
plot(prop.table(table(pp))) + abline(v = dat3_p0, col = 2)
```

The residuals are also looking fairly good for the base model, with no overdispersion.

```{r bestfit dat3 residuals}
DHARMa::testResiduals(bestfit_dat3)
```


### Full model

Since the base model seems to actually be doing a good job of predicting our zeroes correctly, lets add the full suite of (non-correlated) important variables identified in Canham et al. (2021). 

```{r dat3 build full model, echo=FALSE}
build <- buildmer::buildglmmTMB(predicted_wesa ~ n_s + year_c + dos + I(dos^2) + 
                                  (dos + I(dos^2) | year) + (1 | year) + scale(flow) + 
                                  tide + scale(elev_range) +
                                  scale(total_precip) + scale(mean_temp) + scale(u) + 
                                  n_s:scale(flow),
                                dat3, 
                                family = glmmTMB::nbinom2, 
                                buildmerControl = list(direction = 'order'))

(f <- formula(build@model))

m <- buildmer::buildglmmTMB(f, 
                            data = dat3, 
                            buildmerControl = list(direction = 'backward'))

final_f <- formula(m@model)

final_mod <- glmmTMB::glmmTMB(final_f, data = dat3, ziformula = ~., family = glmmTMB::nbinom2)
final_mod <- update(final_mod, ziformula = ~. + raptor_count)
final_mod <- update(final_mod, ziformula = ~. - n_s)
```

```{r}
summary(final_mod)
```

```{r}
sjPlot::plot_model(final_mod, type = "pred")
```

### Diagnostics

```{r wesa make temp plot data}
temp_plot <- broom.mixed::augment(final_mod, dat3)
temp_plot <- janitor::clean_names(temp_plot)
temp_plot <- temp_plot %>% dplyr::select(-start_time, -final_count, -predicted_dunl, -log_wesa, -log_dunl, -p_wesa, -predicted_ratio)
```

```{r wesa temp plot: observed vs predicted}
ggplot(temp_plot, aes(x = predicted_wesa, y = fitted)) +
  geom_point() + 
  ggtitle("Observed vs. Fitted values") +
  xlab("Observed") + 
  ylab("Predicted") +
  theme_minimal()
```


```{r wesa temp plot: heteroskedasticity}
ggplot(temp_plot, aes(x = fitted, y = resid)) +
  geom_point() + 
  ggtitle("Heteroskedasticity",
          subtitle = "Fitted values vs. Residuals") +
  xlab("Fitted") + 
  ylab("Residuals") +
  theme_minimal()
```


```{r wesa temp plot: qq plot}
ggplot(temp_plot, aes(sample = resid)) +
  stat_qq() + 
  stat_qq_line() +
  geom_hline(yintercept = 0,
             linetype = "dashed") +
  ggtitle("Quantile-Quantile") +
  xlab("Theoretical") + 
  ylab("Sample") +
  theme_minimal()
```

```{r wesa slope coeff}
sjPlot::plot_model(final_mod, type = "slope") +
  ggtitle("Coefficient slopes vs Response")
```


```{r wesa vars p1}
(temp_plot %>%
  dplyr::select(year:resid, -fitted) %>%
  tidyr::gather(-resid, key = "var", value = "value") %>%
  dplyr::mutate(value = as.numeric(value)) %>%
  ggplot(aes(x = value, y = resid)) +
  geom_point(size = 0.3) +
  geom_smooth() +
  scale_x_continuous(n.breaks = 3) +
  ggtitle("Full dataset variables vs. Residuals") + 
  ggforce::facet_wrap_paginate(~ var, ncol = 3, nrow = 3, scales = "free", page = 1) +
  theme_minimal())
```

```{r wesa vars p2}
(temp_plot %>%
  dplyr::select(year:resid, -fitted) %>%
  tidyr::gather(-resid, key = "var", value = "value") %>%
  dplyr::mutate(value = as.numeric(value)) %>%
  ggplot(aes(x = value, y = resid)) +
  geom_point(size = 0.3) +
  geom_smooth() +
  scale_x_continuous(n.breaks = 3) +
  ggforce::facet_wrap_paginate(~ var, ncol = 3, nrow = 3, scales = "free", page = 2) +
  theme_minimal())
```

```{r wesa vars p3}
(temp_plot %>%
  dplyr::select(year:resid, -fitted) %>%
  tidyr::gather(-resid, key = "var", value = "value") %>%
  dplyr::mutate(value = as.numeric(value)) %>%
  ggplot(aes(x = value, y = resid)) +
  geom_point(size = 0.3) +
  geom_smooth() +
  scale_x_continuous(n.breaks = 3) +
  ggforce::facet_wrap_paginate(~ var, ncol = 3, nrow = 3, scales = "free", page = 3) +
  theme_minimal())
```

```{r}
temp_plot %>% ggplot(aes(x = n_s, y = resid)) + geom_boxplot() + geom_jitter(alpha = 0.2, size = 0.3)
```


```{r}
temp_plot %>% ggplot(aes(x = tide, y = resid)) + geom_boxplot() + geom_jitter(alpha = 0.2, size = 0.3)
```

### Summary

Residuals show that the model is not doing a great job predicting WESA counts, with clear patterns in the shape of residuals. Given the strong non-linear relationship between WESA counts and day of year, a *general additive modelling* approach may be more suitable.

